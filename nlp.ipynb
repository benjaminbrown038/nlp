{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP\n",
        "\n",
        "### 1. Base Models\n",
        "\n",
        "##### 1. Training Stage\n",
        "\n",
        "##### 2. Achitecture\n",
        "\n",
        "##### 3. Number of Parameters\n",
        "\n",
        "##### 4. Number of Layers\n",
        "\n",
        "##### 5. Number of Attention Heads\n",
        "\n",
        "##### 6. Context Length\n",
        "\n",
        "\n",
        "\n",
        "###  We do not recommend using base language models for conversations. Instead, you can apply post-training, e.g., SFT, RLHF, continued pretraining, etc., on this model."
      ],
      "metadata": {
        "id": "1vlCVpELbZlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Post Training\n",
        "\n",
        "### 1. Supervised Fine Tuning\n",
        "\n",
        "### 2. Reinforcement Learning From Human Feedback\n",
        "\n",
        "### 3. Continued Pretraining / Domain Adaptive Pretraining\n",
        "\n",
        "### 4. Instruction Tuning\n",
        "\n",
        "### 5. Reward Modeling / Preference Supervision\n",
        "\n",
        "### 6. Safety / Policy Fine Tuning\n",
        "\n",
        "### 7. Parameter Efficient Fine Tuning\n",
        "\n",
        "### 8. Calibration Fine Tuning Methods\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "1aYnxU13cacb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Typical High Level Pipeline\n",
        "\n",
        "### 1. Pretraining\n",
        "\n",
        "### 2. Continued Pretraining\n",
        "\n",
        "### 3. SFT / Instruction Tuning\n",
        "\n",
        "### 4. Collect Human Preference Data\n",
        "\n",
        "### 5. Train Reward Model\n",
        "\n",
        "### 6. RLHF Step\n",
        "\n",
        "### 7. Safety Filtering And Targeted Fine Tuning\n",
        "\n",
        "### 8. Evaluation and Iteration"
      ],
      "metadata": {
        "id": "3tgTfGXJcafh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qwen - HuggingFace Language Model\n",
        "\n",
        "\n",
        "## Task\n",
        "\n",
        "### 1. Fill Mask\n",
        "\n",
        "### 2. Question Answering\n",
        "\n",
        "### 3. Summarization\n",
        "\n",
        "### 4. Text Classification\n",
        "\n",
        "### 5. Text Generation\n",
        "\n",
        "### 6. Token Classification\n",
        "\n",
        "### 7. Translation\n",
        "\n",
        "### 8. Custom\n",
        "\n",
        "\n",
        "________________________\n",
        "# Model Tree\n",
        "\n",
        "### 1. Adapters\n",
        "\n",
        "### 2. Fine Tunes\n",
        "\n",
        "### 3. Merges\n",
        "\n",
        "### 4. Quantizations\n",
        "\n",
        "_________________________\n",
        "\n",
        "# Base Model\n",
        "### 1. Training Stage\n",
        "\n",
        "### 2. Achitecture\n",
        "\n",
        "### 3. Number of Parameters\n",
        "\n",
        "### 4. Number of Layers\n",
        "\n",
        "### 5. Number of Attention Heads\n",
        "\n",
        "### 6. Context Length\n"
      ],
      "metadata": {
        "id": "WsZiBu68cai7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "\n",
        "try:\n",
        "\trole = sagemaker.get_execution_role()\n",
        "except ValueError:\n",
        "\tiam = boto3.client('iam')\n",
        "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
        "\n",
        "hyperparameters = {\n",
        "\t'model_name_or_path':'Qwen/Qwen2.5-0.5B',\n",
        "\t'output_dir':'/opt/ml/model'\n",
        "\t# add your remaining hyperparameters\n",
        "\t# more info here https://github.com/huggingface/transformers/tree/v4.49.0/examples/pytorch/language-modeling\n",
        "}\n",
        "\n",
        "# git configuration to download our fine-tuning script\n",
        "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.49.0'}\n",
        "\n",
        "# creates Hugging Face estimator\n",
        "huggingface_estimator = HuggingFace(\n",
        "\tentry_point='run_clm.py',\n",
        "\tsource_dir='./examples/pytorch/language-modeling',\n",
        "\tinstance_type='ml.p3.2xlarge',\n",
        "\tinstance_count=1,\n",
        "\trole=role,\n",
        "\tgit_config=git_config,\n",
        "\ttransformers_version='4.49.0',\n",
        "\tpytorch_version='2.5.1',\n",
        "\tpy_version='py311',\n",
        "\thyperparameters = hyperparameters\n",
        ")\n",
        "\n",
        "# starting the train job\n",
        "huggingface_estimator.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "2rWll5Jyca3Q",
        "outputId": "2e4882b3-9ce2-4704-ca7e-1f1fa4e34f17"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sagemaker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4086639631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuggingface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sagemaker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RAy9Bqmica9f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytm56pPAcbCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kCPiBCETcbHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnxucXq4cbM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IaJ5-shmbZ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uKQXJNl2bZ7i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XGHTNSuSbaAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zGwprqc2baF7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VH7Zr7S8baLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bga4Ix0gbaPl"
      }
    }
  ]
}